{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aux import computeEmissions, isRare, getTrigramCount, getBigramCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return count(x, y) / count(y)\n",
    "def getEmission(emissions, x, y):\n",
    "    if(isRare(emissions, x)):\n",
    "        return emissions['_RARE_'][y]\n",
    "    else:\n",
    "        return emissions[x][y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getq(q, u, v, w):\n",
    "    return q[(u, v, w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllWordsAndTags():\n",
    "    with open('ner_rare.counts') as f_input:\n",
    "        tags = set()\n",
    "        words = set()\n",
    "        for line in f_input:\n",
    "            tokens = line.strip().split()\n",
    "            \n",
    "            if(tokens[1] == 'WORDTAG'):\n",
    "                tag = tokens[2]\n",
    "                tags.add(tag)\n",
    "                word = tokens[3]\n",
    "                words.add(word)\n",
    "    return words, tags\n",
    "\n",
    "#output: T[x] -> set of all tags 'y' s.t. e(x|y) > 0\n",
    "def computeT(emissions):\n",
    "    \n",
    "    T = dict()\n",
    "    words, tags = getAllWordsAndTags()\n",
    "    \n",
    "    for word in words:\n",
    "        tags_with_positive_emissions = []\n",
    "        for tag in tags:\n",
    "            if(getEmission(emissions, word, tag) > 0):\n",
    "                tags_with_positive_emissions.append(tag)\n",
    "        T[word] = tags_with_positive_emissions\n",
    "    \n",
    "    return T\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k is given as input assuming x is 1-indexed\n",
    "def getT(T, x, k, emissions):\n",
    "    if(k == 0 or k == -1):\n",
    "        return ['*']\n",
    "    else:\n",
    "        if(isRare(emissions, x[k - 1])):\n",
    "            return T['_RARE_']\n",
    "        else:\n",
    "            return T[x[k - 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: x[0], x[1], ... x[n - 1]\n",
    "#     : T[x] -> set of all tags 'y' s.t. e(x|y) > 0\n",
    "\n",
    "def tagUsingViterbi(x, emissions, T, q):\n",
    "    \n",
    "    #initialization\n",
    "    pi = dict()\n",
    "    bp = dict()\n",
    "    \n",
    "    pi[(0, '*', '*')] = 1\n",
    "    \n",
    "    #tagged sequence has same length as the input sequence\n",
    "    y = x[:]\n",
    "    \n",
    "    for k in range(1, len(x) + 1):\n",
    "        for u in  getT(T, x, k - 1, emissions):\n",
    "            for v in getT(T, x, k, emissions):\n",
    "                \n",
    "                pi[(k, u, v)] = -1\n",
    "                \n",
    "                for w in getT(T, x, k - 2, emissions):\n",
    "                    \n",
    "                    try:\n",
    "                        this_probability = pi[(k - 1, w, u)] * getq(q, w, u, v) * getEmission(emissions, x[k - 1], v)\n",
    "                        \n",
    "                        if(pi[(k, u, v)]  < this_probability):\n",
    "                            pi[(k, u, v)] = this_probability\n",
    "                            bp[(k, u, v)] = w\n",
    "\n",
    "                    # as of now, exception can be raised by getq only\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "    \n",
    "    \n",
    "    max_prob = -1\n",
    "    n = len(x)\n",
    "    for u in getT(T, x, n - 1, emissions):\n",
    "        for v in getT(T, x, n, emissions):\n",
    "            try:\n",
    "                if(max_prob < pi[(n, u, v)]) * getq(q, u, v, 'STOP'):\n",
    "                    max_prob = pi[(n, u, v)] * getq(q, u, v, 'STOP')\n",
    "                    y[n - 2] = u\n",
    "                    y[n - 1] = v\n",
    "            except Exception as e:\n",
    "                pass\n",
    "              \n",
    "\n",
    "    for k in range(n - 3, -1, -1):\n",
    "        y[k] = bp[(k + 2 + 1, y[k + 1], y[k + 2])]\n",
    "        \n",
    "    return (y, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function assumes that y is 1-indexed\n",
    "def gety(y, k):\n",
    "    if(k <= 0):\n",
    "        return '*'\n",
    "    else:\n",
    "        return y[k - 1]\n",
    "def getLogLikelihood(x, y, pi):\n",
    "    log_likelihood = []\n",
    "    for k in range(1, len(x) + 1):\n",
    "        log_prob = np.log(pi[(k, gety(y, k - 1), gety(y, k))])\n",
    "        log_likelihood.append(log_prob)\n",
    "    \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeThisSentence(f_output, x, y, log_likelihood):\n",
    "    for (word, tag, log_prob) in zip(x, y, log_likelihood):\n",
    "        this_line = ' '.join((word, tag, '{}'.format(log_prob)))\n",
    "        this_line = this_line + '\\n'\n",
    "        f_output.write(this_line)\n",
    "    f_output.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeq():\n",
    "    count_of_trigrams = dict()\n",
    "    count_of_bigrams = dict()\n",
    "    \n",
    "    with open('ner_rare.counts') as f_input:\n",
    "        for line in f_input:\n",
    "            tokens = line.strip().split()\n",
    "            if(tokens[1] == '2-GRAM'):\n",
    "                u, v = tokens[2], tokens[3]\n",
    "                count_of_bigrams[(u, v)] = int(tokens[0])\n",
    "            elif(tokens[1] == '3-GRAM'):\n",
    "                u, v, w = tokens[2], tokens[3], tokens[4]\n",
    "                count_of_trigrams[(u, v, w)] = int(tokens[0])\n",
    "    q = dict()\n",
    "    for (u, v, w) in count_of_trigrams:\n",
    "        q[(u, v, w)] = float(count_of_trigrams[(u, v, w)])/ float(count_of_bigrams[(u, v)])\n",
    "        \n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial parameters\n",
    "emissions = computeEmissions()\n",
    "T = computeT(emissions)\n",
    "q = computeq()\n",
    "\n",
    "with open('ner_dev.dat') as f_input, open('5_2.txt', 'w') as f_output:\n",
    "    x = []\n",
    "    for line in f_input:\n",
    "        tokens = line.strip().split()\n",
    "        \n",
    "        if(len(tokens) > 0):\n",
    "            x.append(tokens[0])\n",
    "        else:\n",
    "            #x has buffered a sentence\n",
    "            y, pi = tagUsingViterbi(x, emissions, T, q)\n",
    "            log_likelihood = getLogLikelihood(x, y, pi)\n",
    "            \n",
    "            writeThisSentence(f_output, x, y, log_likelihood)\n",
    "            \n",
    "            x = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
